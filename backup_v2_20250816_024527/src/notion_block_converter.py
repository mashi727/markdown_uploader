"""
Markdownã‹ã‚‰Notionãƒ–ãƒ­ãƒƒã‚¯ã¸ã®å¤‰æ›æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import re
import logging
from pathlib import Path
from typing import List, Dict, Any, Set

from markdown_it import MarkdownIt

from .config import Config
from .markdown_parser import MarkdownParser
from .image_uploader import ImageUploader


class NotionBlockConverter:
    """Markdownã‹ã‚‰Notionãƒ–ãƒ­ãƒƒã‚¯ã¸ã®å¤‰æ›ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Config):
        self.config = config
        self.parser = MarkdownParser()
        self.image_uploader = ImageUploader(config)
        self.md = MarkdownIt('commonmark', {'linkify': True})
        
        # å‡¦ç†æ¸ˆã¿ç”»åƒã®è¿½è·¡
        self.processed_images: Set[str] = set()
    
    def convert_markdown_to_blocks(self, md_text: str, md_dir: Path) -> List[Dict[str, Any]]:
        """Markdownãƒ†ã‚­ã‚¹ãƒˆã‚’Notionãƒ–ãƒ­ãƒƒã‚¯ã«å¤‰æ›ã™ã‚‹"""
        # remote-claudeå½¢å¼ã®å‰å‡¦ç†
        md_text = self.parser.preprocess_remote_claude_format(md_text)
        
        # Obsidianã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒªãƒ³ã‚¯ã‚’å¤‰æ›
        md_text = re.sub(r"\[\[(.+?)\]\]", r"\1", md_text)
        
        # ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å‡¦ç†
        md_text = self._process_callouts(md_text)
        
        # ç›´æ¥çš„ã«ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã‚’æ¤œå‡ºã—ã¦å¤‰æ›
        blocks = []
        self._process_text_with_block_math(md_text, md_dir, blocks)
        
        return self._validate_blocks(blocks)
    
    def _process_callouts(self, md_text: str) -> str:
        """Obsidianã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å‡¦ç†ã™ã‚‹"""
        lines = md_text.split('\n')
        processed_lines = []
        i = 0
        
        while i < len(lines):
            line = lines[i]
            
            # ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®é–‹å§‹ã‚’æ¤œå‡º
            callout_match = re.match(r'^>\s*\[!([A-Z]+)\](?:\s+(.+?))?\s*$', line)
            
            if callout_match:
                callout_type = callout_match.group(1)
                title = callout_match.group(2) or callout_type.title()
                emoji = self.parser.CALLOUT_TYPES.get(callout_type, 'ğŸ“Œ')
                
                # ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãƒ–ãƒ­ãƒƒã‚¯ã‚’åé›†
                content_lines = []
                i += 1
                
                while i < len(lines) and lines[i].startswith('>'):
                    content_line = lines[i][1:].lstrip()
                    if content_line:  # ç©ºè¡Œã§ãªã„å ´åˆã®ã¿è¿½åŠ 
                        content_lines.append(content_line)
                    i += 1
                
                # Notionå½¢å¼ã«å¤‰æ›ï¼ˆã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆãƒœãƒƒã‚¯ã‚¹é¢¨ï¼‰
                processed_lines.append('')  # å‰ã«ç©ºè¡Œ
                processed_lines.append(f'**{emoji} {title}**')
                processed_lines.append('')  # ã‚¿ã‚¤ãƒˆãƒ«å¾Œã«ç©ºè¡Œ
                
                # å†…å®¹ã‚’å›²ã¿æ é¢¨ã«è¡¨ç¾
                if content_lines:
                    # å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦å†…å®¹ã‚’è¿½åŠ 
                    for content_line in content_lines:
                        processed_lines.append(f'> {content_line}')
                
                processed_lines.append('')  # å¾Œã«ç©ºè¡Œ
            else:
                processed_lines.append(line)
                i += 1
        
        return '\n'.join(processed_lines)
    
    def _process_text_with_block_math(self, md_text: str, md_dir: Path, blocks: List[Dict]):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã‚’è€ƒæ…®ã—ã¦å‡¦ç†ã™ã‚‹"""
        # ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆæ”¹è¡Œã‚’å«ã‚€ï¼‰
        block_math_pattern = r'\$\$\s*(.*?)\s*\$\$'
        
        # æœ€åˆã«å…¨ã¦ã®ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã‚’è¦‹ã¤ã‘ã‚‹
        block_math_matches = list(re.finditer(block_math_pattern, md_text, re.DOTALL))
        
        if not block_math_matches:
            # ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ãŒãªã„å ´åˆã¯é€šå¸¸ã®å‡¦ç†
            self._process_regular_markdown(md_text, md_dir, blocks)
            return
        
        last_end = 0
        
        for match in block_math_matches:
            start, end = match.span()
            
            # æ•°å¼ã®å‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†
            if start > last_end:
                before_text = md_text[last_end:start].strip()
                if before_text:
                    self._process_regular_markdown(before_text, md_dir, blocks)
            
            # ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã‚’å‡¦ç†
            math_content = match.group(1).strip()
            blocks.append({
                'object': 'block',
                'type': 'equation',
                'equation': {'expression': math_content}
            })
            logging.info(f"ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {math_content[:50]}...")
            
            last_end = end
        
        # æœ€å¾Œã®æ•°å¼ã®å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†
        if last_end < len(md_text):
            after_text = md_text[last_end:].strip()
            if after_text:
                self._process_regular_markdown(after_text, md_dir, blocks)
    
    def _process_regular_markdown(self, md_text: str, md_dir: Path, blocks: List[Dict]):
        """é€šå¸¸ã®Markdownãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹"""
        tokens = self.md.parse(md_text)
        i = 0
        
        # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æ•°å¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆè¡Œå†…ã®$...$ï¼‰
        inline_math_pattern = r'\$([^$\n]+)\$'
        
        while i < len(tokens):
            token = tokens[i]
            t = token.type
            
            if t == 'heading_open':
                i = self._process_heading(tokens, i, blocks)
            elif t in ('bullet_list_open', 'ordered_list_open'):
                i = self._process_list(tokens, i, blocks)
            elif t == 'paragraph_open':
                i = self._process_paragraph(tokens, i, blocks, md_dir, inline_math_pattern)
            elif t == 'inline':
                i = self._process_inline(tokens, i, blocks, md_dir)
            elif t == 'fence':
                i = self._process_code_block(tokens, i, blocks)
            elif t == 'blockquote_open':
                i = self._process_blockquote(tokens, i, blocks)
            elif t == 'hr':
                blocks.append({'object': 'block', 'type': 'divider', 'divider': {}})
                i += 1
            else:
                i += 1
    
    def _process_heading(self, tokens, i: int, blocks: List[Dict]) -> int:
        """è¦‹å‡ºã—ã‚’å‡¦ç†ã™ã‚‹ï¼ˆçµµæ–‡å­—ä»˜ãã®è¦‹å‡ºã—ã«å¯¾å¿œï¼‰"""
        token = tokens[i]
        lvl = int(token.tag[1])
        content = tokens[i+1].content
        
        # å®Ÿè¡Œè¨˜éŒ²ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã«ç‰¹åˆ¥ãªå‡¦ç†ã‚’é©ç”¨
        if 'ğŸ“Š å®Ÿè¡Œè¨˜éŒ²:' in content or 'ğŸ’¬ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' in content or 'âœ¨ çµæœ' in content:
            # ãƒˆã‚°ãƒ«å¯èƒ½ãªã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¨ã—ã¦å‡¦ç†
            blk = f"heading_{min(lvl, 3)}"
            blocks.append({
                'object': 'block',
                'type': blk,
                blk: {
                    'rich_text': [{'type': 'text', 'text': {'content': content}}],
                    'is_toggleable': True  # Notionã§ãƒˆã‚°ãƒ«å¯èƒ½ã«
                }
            })
        else:
            blk = f"heading_{lvl}" if lvl <= 3 else 'paragraph'
            blocks.append({
                'object': 'block',
                'type': blk,
                blk: {'rich_text': [{'type': 'text', 'text': {'content': content}}]}
            })
        
        return i + 3
    
    def _process_list(self, tokens, i: int, blocks: List[Dict]) -> int:
        """ãƒªã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹"""
        list_type = 'numbered_list_item' if tokens[i].type == 'ordered_list_open' else 'bulleted_list_item'
        i += 1
        
        while tokens[i].type not in ('bullet_list_close', 'ordered_list_close'):
            if tokens[i].type == 'list_item_open':
                txt = tokens[i+2].content
                
                # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ãƒªã‚¹ãƒˆé …ç›®ã‚’ç‰¹åˆ¥ã«å‡¦ç†
                if txt.startswith('**') and ':' in txt:
                    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚’æ•´å½¢
                    blocks.append({
                        'object': 'block',
                        'type': list_type,
                        list_type: {
                            'rich_text': [{'type': 'text', 'text': {'content': txt}}],
                            'color': 'gray_background'  # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’è¦–è¦šçš„ã«åŒºåˆ¥
                        }
                    })
                else:
                    # é€šå¸¸ã®ãƒªã‚¹ãƒˆé …ç›®
                    links_processed = self._process_markdown_links_as_labeled_bookmarks(txt, blocks)
                    
                    if not links_processed:
                        blocks.append({
                            'object': 'block',
                            'type': list_type,
                            list_type: {'rich_text': [{'type': 'text', 'text': {'content': txt}}]}
                        })
                
                i += 5
                continue
            i += 1
        
        return i + 1
    
    def _process_paragraph(self, tokens, i: int, blocks: List[Dict], md_dir: Path, inline_math_pattern: str) -> int:
        """æ®µè½ã‚’å‡¦ç†ã™ã‚‹"""
        txt = tokens[i+1].content.strip()
        if not txt:
            return i + 3
        
        # ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆ$$...$$ï¼‰
        block_math_pattern = r'\$\$\s*(.*?)\s*\$\$'
        block_math_match = re.search(block_math_pattern, txt, re.DOTALL)
        
        if block_math_match:
            # ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã€é©åˆ‡ã«å‡¦ç†
            math_content = block_math_match.group(1).strip()
            blocks.append({
                'object': 'block',
                'type': 'equation',
                'equation': {'expression': math_content}
            })
            logging.info(f"æ®µè½å†…ã®ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {math_content[:30]}...")
            return i + 3
        
        # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æ•°å¼ã‚’ãƒã‚§ãƒƒã‚¯ï¼ˆè¡Œå†…ã®$...$ï¼‰
        inline_math_matches = list(re.finditer(inline_math_pattern, txt))
        if inline_math_matches:
            self._process_inline_math(txt, inline_math_matches, blocks)
        else:
            # ç”»åƒã‚’å«ã‚€ã‹ã©ã†ã‹ã‚’ãƒã‚§ãƒƒã‚¯
            has_image = self._process_paragraph_images(tokens[i+1], md_dir, blocks)
            
            # ç”»åƒã‚’å«ã¾ãªã„å ´åˆã®ã¿ãƒªãƒ³ã‚¯ã¨ã—ã¦å‡¦ç†
            if not has_image:
                self._process_paragraph_text(txt, blocks)
        
        return i + 3
    
    def _process_inline_math(self, txt: str, math_matches: List, blocks: List[Dict]):
        """ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æ•°å¼ã‚’å‡¦ç†ã™ã‚‹ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®é †åºã‚’ä¿æŒï¼‰"""
        last_end = 0
        
        # ãƒ†ã‚­ã‚¹ãƒˆã¨æ•°å¼ã‚’æ–‡æ›¸ã®é †åºé€šã‚Šã«å‡¦ç†
        for match in math_matches:
            start, end = match.span()
            
            # æ•°å¼ã®å‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å…ˆã«è¿½åŠ ï¼ˆç©ºæ–‡å­—åˆ—ã¯é™¤ãï¼‰
            if start > last_end:
                prefix_text = txt[last_end:start].strip()
                if prefix_text:  # ç©ºæ–‡å­—åˆ—ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
                    blocks.append({
                        'object': 'block',
                        'type': 'paragraph',
                        'paragraph': {'rich_text': [{'type': 'text', 'text': {'content': prefix_text}}]}
                    })
            
            # æ•°å¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’è¿½åŠ ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã®å¾Œã«é…ç½®ï¼‰
            math_content = match.group(1)
            blocks.append({
                'object': 'block',
                'type': 'equation',
                'equation': {'expression': math_content}
            })
            logging.info(f"ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æ•°å¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {math_content[:30]}...")
            
            # æ¬¡ã®ãƒ«ãƒ¼ãƒ—ã®ãŸã‚ã«çµ‚äº†ä½ç½®ã‚’æ›´æ–°
            last_end = end
        
        # æœ€å¾Œã®æ•°å¼å¾Œã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ ï¼ˆç©ºæ–‡å­—åˆ—ã¯é™¤ãï¼‰
        if last_end < len(txt):
            suffix_text = txt[last_end:].strip()
            if suffix_text:  # ç©ºæ–‡å­—åˆ—ãƒã‚§ãƒƒã‚¯ã‚’è¿½åŠ 
                blocks.append({
                    'object': 'block',
                    'type': 'paragraph',
                    'paragraph': {'rich_text': [{'type': 'text', 'text': {'content': suffix_text}}]}
                })
    
    def _process_paragraph_images(self, token, md_dir: Path, blocks: List[Dict]) -> bool:
        """æ®µè½å†…ã®ç”»åƒã‚’å‡¦ç†ã™ã‚‹"""
        has_image = False
        for child in token.children or []:
            if child.type == 'image':
                has_image = True
                raw = child.attrs.get('src', '') if child.attrs else ''
                if raw not in self.processed_images:
                    self.processed_images.add(raw)
                    src = raw if raw.startswith(('http://', 'https://')) else self.image_uploader.get_image_url((md_dir/raw).resolve())
                    if src:
                        blocks.append({
                            'object': 'block',
                            'type': 'image',
                            'image': {'type': 'external', 'external': {'url': src}}
                        })
                        logging.info(f"ç”»åƒãƒ–ãƒ­ãƒƒã‚¯ã‚’è¿½åŠ ã—ã¾ã—ãŸ: src={src}")
        return has_image
    
    def _process_paragraph_text(self, txt: str, blocks: List[Dict]):
        """æ®µè½ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã™ã‚‹"""
        links_processed = self._process_markdown_links_as_labeled_bookmarks(txt, blocks)
        
        if not links_processed:
            text_parts = self.parser.split_long_text(txt, self.config.max_rich_text_length)
            for part in text_parts:
                blocks.append({
                    'object': 'block',
                    'type': 'paragraph',
                    'paragraph': {'rich_text': [{'type': 'text', 'text': {'content': part}}]}
                })
    
    def _process_inline(self, tokens, i: int, blocks: List[Dict], md_dir: Path) -> int:
        """ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³è¦ç´ ã‚’å‡¦ç†ã™ã‚‹"""
        token = tokens[i]
        handled = False
        
        # ç”»åƒã®å‡¦ç†
        for child in token.children or []:
            if child.type == 'image':
                raw = child.attrs.get('src', '') if child.attrs else ''
                if raw not in self.processed_images:
                    self.processed_images.add(raw)
                    src = raw if raw.startswith(('http://', 'https://')) else self.image_uploader.get_image_url((md_dir/raw).resolve())
                    if src:
                        blocks.append({
                            'object': 'block',
                            'type': 'image',
                            'image': {'type': 'external', 'external': {'url': src}}
                        })
                        logging.info(f"ç”»åƒãƒ–ãƒ­ãƒƒã‚¯ã‚’è¿½åŠ ã—ã¾ã—ãŸ (inline): src={src}")
                        handled = True
        
        if not handled:
            txt = token.content.strip()
            if txt:
                self._process_paragraph_text(txt, blocks)
        
        return i + 1
    
    def _process_code_block(self, tokens, i: int, blocks: List[Dict]) -> int:
        """ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‡¦ç†ã™ã‚‹"""
        token = tokens[i]
        code = token.content
        info_str = token.info.strip()
        
        # è¨€èªæƒ…å ±ã‚’å–å¾—
        lang = self._determine_code_language(info_str)
        
        # æ•°å¼ãƒ–ãƒ­ãƒƒã‚¯ã‹ã©ã†ã‹ã‚’å„ªå…ˆçš„ã«ãƒã‚§ãƒƒã‚¯
        if self._is_math_block(lang, code):
            # æ•°å¼ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦å‡¦ç†
            blocks.append({
                'object': 'block',
                'type': 'equation',
                'equation': {'expression': code.strip()}  # å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
            })
            logging.info(f"æ•°å¼ãƒ–ãƒ­ãƒƒã‚¯ã‚’è¿½åŠ ã—ã¾ã—ãŸ: {code.strip()[:30]}...")
            return i + 1
        
        # é€šå¸¸ã®ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦å‡¦ç†
        if len(code) > self.config.max_rich_text_length:
            self._process_long_code_block(code, lang, blocks)
        else:
            blocks.append({
                'object': 'block',
                'type': 'code',
                'code': {
                    'language': lang,
                    'rich_text': [{'type': 'text', 'text': {'content': code}}]
                }
            })
        
        return i + 1
    
    def _determine_code_language(self, info_str: str) -> str:
        """ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã®è¨€èªã‚’æ±ºå®šã™ã‚‹"""
        if not info_str:
            return 'plain text'
        
        raw_lang = info_str.split()[0].lower()
        
        language_mapping = {
            'sh': 'bash',
            'shell': 'bash',
            'js': 'javascript',
            'javascript': 'javascript',
            'math': 'math',
            'latex': 'latex',
            'tex': 'latex',  # texã‚‚latexã¨ã—ã¦æ‰±ã†
            'puml': 'plain text',
            'plantuml': 'plain text',
            'paul': 'plain text',
            'gnuplot': 'plain text',
            'python': 'python',
            'py': 'python',
            'java': 'java',
            'c': 'c',
            'cpp': 'cpp',
            'c++': 'cpp',
            'csharp': 'csharp',
            'cs': 'csharp',
            'ruby': 'ruby',
            'rb': 'ruby',
            'go': 'go',
            'rust': 'rust',
            'rs': 'rust',
            'html': 'html',
            'css': 'css',
            'xml': 'xml',
            'json': 'json',
            'yaml': 'yaml',
            'yml': 'yaml',
            'sql': 'sql',
            'r': 'r',
            'matlab': 'matlab',
            'swift': 'swift',
            'kotlin': 'kotlin',
            'kt': 'kotlin',
            'php': 'php',
            'perl': 'perl',
            'scala': 'scala',
            'haskell': 'haskell',
            'hs': 'haskell',
            'typescript': 'typescript',
            'ts': 'typescript',
            'markdown': 'markdown',
            'md': 'markdown'
        }
        
        return language_mapping.get(raw_lang, raw_lang)
    
    def _is_math_block(self, lang: str, content: str) -> bool:
        """ãƒ–ãƒ­ãƒƒã‚¯ãŒæ•°å¼ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ï¼ˆã‚ˆã‚Šå³å¯†ãªåˆ¤å®šï¼‰"""
        # LaTeXæ–‡æ›¸ã®å ´åˆã¯æ•°å¼ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦æ‰±ã‚ãªã„
        content_stripped = content.strip()
        
        # LaTeXæ–‡æ›¸ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        latex_document_indicators = [
            r'\\documentclass',
            r'\\usepackage',
            r'\\begin{document}',
            r'\\end{document}',
            r'\\title{',
            r'\\author{',
            r'\\maketitle',
            r'\\section{',
            r'\\subsection{',
            r'\\chapter{',
            r'\\tableofcontents',
            r'\\bibliography'
        ]
        
        # LaTeXæ–‡æ›¸ã®å ´åˆã¯ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦æ‰±ã†
        if any(indicator in content_stripped for indicator in latex_document_indicators):
            return False
        
        # æ˜ç¤ºçš„ãªæ•°å­¦è¨€èªæŒ‡å®šï¼ˆãŸã ã—ã€æ–‡æ›¸æ§‹é€ ã§ãªã„å ´åˆã®ã¿ï¼‰
        if lang == 'math':
            return True
        
        # å†…å®¹ã«ã‚ˆã‚‹åˆ¤å®šï¼ˆã‚ˆã‚Šå³å¯†ã«ï¼‰
        # LaTeXæ•°å¼ã®å…¸å‹çš„ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
        math_indicators = [
            # æ•°å¼ç’°å¢ƒ
            r'\\begin{equation',
            r'\\begin{align',
            r'\\begin{gather',
            r'\\begin{matrix',
            r'\\begin{pmatrix',
            r'\\begin{bmatrix',
            r'\\begin{cases',
            # æ•°å¼ã‚³ãƒãƒ³ãƒ‰
            r'\\frac{',
            r'\\sum',
            r'\\int',
            r'\\lim',
            r'\\prod',
            # æ¼”ç®—å­
            r'\\nabla',
            r'\\partial',
            # ã‚®ãƒªã‚·ãƒ£æ–‡å­—ï¼ˆã‚ˆãä½¿ã‚ã‚Œã‚‹ã‚‚ã®ï¼‰
            r'\\alpha',
            r'\\beta',
            r'\\gamma',
            r'\\delta',
            r'\\epsilon',
            r'\\theta',
            r'\\lambda',
            r'\\mu',
            r'\\pi',
            r'\\sigma',
            r'\\phi',
            r'\\omega',
            # æ‹¬å¼§
            r'\\left',
            r'\\right',
            # ãƒ•ã‚©ãƒ³ãƒˆ
            r'\\mathbf',
            r'\\mathcal',
            r'\\mathrm',
            # æ¼”ç®—è¨˜å·
            r'\\cdot',
            r'\\times',
            r'\\div',
            # é›†åˆè¨˜å·
            r'\\cap',
            r'\\cup',
            r'\\subset',
            r'\\in',
            # è«–ç†è¨˜å·
            r'\\forall',
            r'\\exists',
            r'\\Rightarrow'
        ]
        
        # è¤‡æ•°ã®æ•°å¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒå«ã¾ã‚Œã¦ã„ã‚‹å ´åˆã«ã‚ˆã‚Šç¢ºå®Ÿ
        pattern_count = sum(1 for pattern in math_indicators if pattern in content_stripped)
        
        # 3ã¤ä»¥ä¸Šã®æ•°å¼ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒã‚ã‚‹å ´åˆï¼ˆã‚ˆã‚Šå³å¯†ã«ï¼‰
        if pattern_count >= 3:
            return True
        
        # æ˜ç¢ºãªæ•°å¼ç’°å¢ƒã®å ´åˆ
        math_env_patterns = [
            r'\\begin{equation',
            r'\\begin{align',
            r'\\begin{gather',
            r'\\begin{matrix',
            r'\\begin{pmatrix',
            r'\\begin{bmatrix'
        ]
        if any(pattern in content_stripped for pattern in math_env_patterns):
            return True
        
        return False
    
    def _process_long_code_block(self, code: str, lang: str, blocks: List[Dict]):
        """é•·ã„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’åˆ†å‰²ã—ã¦å‡¦ç†ã™ã‚‹"""
        logging.info(f"é•·ã„ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’åˆ†å‰²ã—ã¾ã™ (é•·ã•: {len(code)}æ–‡å­—)")
        code_parts = self.parser.split_long_text(code, self.config.max_rich_text_length)
        
        for idx, part in enumerate(code_parts):
            blocks.append({
                'object': 'block',
                'type': 'code',
                'code': {
                    'language': lang,
                    'rich_text': [{'type': 'text', 'text': {'content': part}}]
                }
            })
            
            if idx < len(code_parts) - 1:
                blocks.append({
                    'object': 'block',
                    'type': 'paragraph',
                    'paragraph': {
                        'rich_text': [{'type': 'text', 'text': {'content': f"(ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯åˆ†å‰² {idx+1}/{len(code_parts)})"}}]
                    }
                })
    
    def _process_blockquote(self, tokens, i: int, blocks: List[Dict]) -> int:
        """å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‡¦ç†ã™ã‚‹ï¼ˆã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆé¢¨ã®å¼•ç”¨ã«ã‚‚å¯¾å¿œï¼‰"""
        qt = tokens[i+2].content
        
        # remote-claudeå½¢å¼ã®å¼•ç”¨ï¼ˆãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéƒ¨åˆ†ï¼‰ã‚’ç‰¹åˆ¥ã«å‡¦ç†
        if 'å…¥åŠ›ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' in qt or 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ' in qt:
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆç”¨ã®ç‰¹åˆ¥ãªå¼•ç”¨ã‚¹ã‚¿ã‚¤ãƒ«
            text_parts = self.parser.split_long_text(qt, self.config.max_rich_text_length)
            for part in text_parts:
                blocks.append({
                    'object': 'block',
                    'type': 'callout',
                    'callout': {
                        'rich_text': [{'type': 'text', 'text': {'content': part}}],
                        'icon': {'emoji': 'ğŸ’¬'},
                        'color': 'blue_background'
                    }
                })
        else:
            # é€šå¸¸ã®å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯
            links_processed = self._process_markdown_links_as_labeled_bookmarks(qt, blocks)
            
            if not links_processed:
                text_parts = self.parser.split_long_text(qt, self.config.max_rich_text_length)
                for part in text_parts:
                    blocks.append({
                        'object': 'block',
                        'type': 'quote',
                        'quote': {'rich_text': [{'type': 'text', 'text': {'content': part}}]}
                    })
        
        return i + 5
    
    def _process_markdown_links_as_labeled_bookmarks(self, text: str, blocks: List[Dict]) -> bool:
        """Markdownã®ãƒªãƒ³ã‚¯ã‚’è¦‹å‡ºã—ä»˜ããƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦å‡¦ç†ã™ã‚‹"""
        links = self.parser.extract_markdown_links(text)
        
        if not links:
            return False
        
        for link in links:
            link_text = link['text']
            url = link['url']
            
            # ã¾ãšè¦‹å‡ºã—ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿½åŠ 
            blocks.append({
                'object': 'block',
                'type': 'paragraph',
                'paragraph': {'rich_text': [{'type': 'text', 'text': {'content': link_text}}]}
            })
            
            # æ¬¡ã«URLã‚’ãƒ–ãƒƒã‚¯ãƒãƒ¼ã‚¯ã¾ãŸã¯åŸ‹ã‚è¾¼ã¿ã¨ã—ã¦è¿½åŠ 
            if self.parser.is_video_link(url, self.config.video_domains):
                blocks.append({'object': 'block', 'type': 'embed', 'embed': {'url': url}})
            else:
                blocks.append({'object': 'block', 'type': 'bookmark', 'bookmark': {'url': url}})
        
        return True
    
    def _validate_blocks(self, blocks: List[Dict]) -> List[Dict]:
        """ãƒ–ãƒ­ãƒƒã‚¯ã®å¦¥å½“æ€§ã‚’ç¢ºèªã™ã‚‹"""
        valid_blocks = []
        for idx, block in enumerate(blocks):
            block_type = block.get('type')
            if block_type and block.get(block_type) is not None:
                valid_blocks.append(block)
            else:
                logging.warning(f"ç„¡åŠ¹ãªãƒ–ãƒ­ãƒƒã‚¯ã‚’ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™ (index {idx}): {block}")
        
        return valid_blocks
