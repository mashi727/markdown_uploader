"""
Markdownã‹ã‚‰Notionãƒ–ãƒ­ãƒƒã‚¯ã¸ã®å¤‰æ›æ©Ÿèƒ½ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«
"""

import re
import logging
from pathlib import Path
from typing import List, Dict, Any, Set, Optional

from markdown_it import MarkdownIt

from .config import Config
from .markdown_parser import MarkdownParser
from .image_uploader import ImageUploader


class NotionBlockConverter:
    """Markdownã‹ã‚‰Notionãƒ–ãƒ­ãƒƒã‚¯ã¸ã®å¤‰æ›ã‚’æ‹…å½“ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config: Config):
        self.config = config
        self.parser = MarkdownParser()
        self.image_uploader = ImageUploader(config)
        self.md = MarkdownIt('commonmark', {'linkify': True})
        
        # å‡¦ç†æ¸ˆã¿ç”»åƒã®è¿½è·¡
        self.processed_images: Set[str] = set()
    
    def convert_markdown_to_blocks(self, md_text: str, md_dir: Path) -> List[Dict[str, Any]]:
        """Markdownãƒ†ã‚­ã‚¹ãƒˆã‚’Notionãƒ–ãƒ­ãƒƒã‚¯ã«å¤‰æ›ã™ã‚‹"""
        # remote-claudeå½¢å¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š
        is_remote_claude = self._is_remote_claude_format(md_text)
        
        if is_remote_claude:
            # remote-claudeå½¢å¼ã®ç‰¹åˆ¥ãªå‡¦ç†
            logging.info("remote-claudeå½¢å¼ã‚’æ¤œå‡ºã—ã¾ã—ãŸ")
            return self._convert_remote_claude_format(md_text, md_dir)
        else:
            # é€šå¸¸ã®Markdownå‡¦ç†
            logging.info("é€šå¸¸ã®Markdownå½¢å¼ã¨ã—ã¦å‡¦ç†ã—ã¾ã™")
            # Obsidianã‚¹ã‚¿ã‚¤ãƒ«ã®ãƒªãƒ³ã‚¯ã‚’å¤‰æ›
            md_text = re.sub(r"\[\[(.+?)\]\]", r"\1", md_text)
            
            # ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å‡¦ç†
            md_text = self._process_callouts(md_text)
            
            # ç›´æ¥çš„ã«ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã‚’æ¤œå‡ºã—ã¦å¤‰æ›
            blocks = []
            self._process_text_with_block_math(md_text, md_dir, blocks)
            
            return self._validate_blocks(blocks)
    
    def _is_remote_claude_format(self, md_text: str) -> bool:
        """remote-claudeå½¢å¼ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
        # ã‚ˆã‚Šå³å¯†ãªåˆ¤å®šãƒ‘ã‚¿ãƒ¼ãƒ³
        patterns = [
            r'## å®Ÿè¡Œè¨˜éŒ²:\s*\d{4}-\d{2}-\d{2}',
            r'\*\*æ¥ç¶šå…ˆ:\*\*',
            r'\*\*ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«:\*\*',
            r'### ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ',
            r'### çµæœ'
        ]
        
        # å°‘ãªãã¨ã‚‚3ã¤ä»¥ä¸Šã®ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒãƒãƒƒãƒã™ã‚Œã°remote-claudeå½¢å¼ã¨åˆ¤å®š
        matches = sum(1 for pattern in patterns if re.search(pattern, md_text))
        return matches >= 3
    
    def _convert_remote_claude_format(self, md_text: str, md_dir: Path) -> List[Dict[str, Any]]:
        """remote-claudeå½¢å¼ã‚’ç‰¹åˆ¥ã«å‡¦ç†"""
        blocks = []
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è§£æ
        sections = self._parse_remote_claude_sections(md_text)
        
        logging.info(f"è§£æã•ã‚ŒãŸã‚»ã‚¯ã‚·ãƒ§ãƒ³: {sections.keys()}")
        
        # å®Ÿè¡Œè¨˜éŒ²ãƒ˜ãƒƒãƒ€ãƒ¼
        if sections.get('execution_header'):
            blocks.append({
                'object': 'block',
                'type': 'heading_2',
                'heading_2': {
                    'rich_text': [{'type': 'text', 'text': {'content': f"ğŸ“Š {sections['execution_header']}"}}]
                }
            })
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
        if sections.get('metadata'):
            for meta_line in sections['metadata']:
                blocks.append({
                    'object': 'block',
                    'type': 'bulleted_list_item',
                    'bulleted_list_item': {
                        'rich_text': [{'type': 'text', 'text': {'content': meta_line}}],
                        'color': 'gray_background'
                    }
                })
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³
        if sections.get('prompt_title'):
            blocks.append({
                'object': 'block',
                'type': 'heading_3',
                'heading_3': {
                    'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ’¬ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ'}}]
                }
            })
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹ã‚’å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã¨ã—ã¦è¿½åŠ 
            if sections.get('prompt_content'):
                prompt_text = sections['prompt_content'].strip()
                logging.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹: {prompt_text[:100]}...")
                
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã¨ã—ã¦è¡¨ç¤º
                blocks.append({
                    'object': 'block',
                    'type': 'callout',
                    'callout': {
                        'rich_text': [{'type': 'text', 'text': {'content': prompt_text}}],
                        'icon': {'emoji': 'ğŸ’¬'},
                        'color': 'blue_background'
                    }
                })
        
        # çµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆãƒˆã‚°ãƒ«å†…ã«é…ç½®ï¼‰
        if sections.get('result_content'):
            result_content = sections['result_content'].strip()
            logging.info(f"çµæœå†…å®¹ã®é•·ã•: {len(result_content)} æ–‡å­—")
            
            # çµæœã®ãƒ˜ãƒƒãƒ€ãƒ¼
            blocks.append({
                'object': 'block',
                'type': 'heading_3',
                'heading_3': {
                    'rich_text': [{'type': 'text', 'text': {'content': 'âœ¨ çµæœ'}}]
                }
            })
            
            # çµæœãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½œæˆ
            result_children = self._create_result_blocks(result_content, md_dir)
            
            logging.info(f"çµæœãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(result_children)}")
            
            # ãƒˆã‚°ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½œæˆã—ã€å­è¦ç´ ã‚’å«ã‚ã‚‹
            toggle_block = {
                'object': 'block',
                'type': 'toggle',
                'toggle': {
                    'rich_text': [{'type': 'text', 'text': {'content': 'ğŸ“– å®Ÿè¡Œçµæœã‚’è¡¨ç¤º'}}],
                    'color': 'purple_background'
                }
            }
            
            # å­è¦ç´ ãŒã‚ã‚‹å ´åˆã®ã¿childrenã‚’è¿½åŠ 
            if result_children:
                toggle_block['toggle']['children'] = result_children
            
            blocks.append(toggle_block)
        else:
            logging.warning("çµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        
        return self._validate_blocks(blocks)
    
    def _parse_remote_claude_sections(self, md_text: str) -> Dict[str, Any]:
        """remote-claudeå½¢å¼ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è§£æï¼ˆæ”¹å–„ç‰ˆï¼‰"""
        sections = {}
        lines = md_text.split('\n')
        
        current_section = None
        prompt_lines = []
        result_lines = []
        metadata_lines = []
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®å¢ƒç•Œã‚’è¦‹ã¤ã‘ã‚‹
        prompt_start = -1
        result_start = -1
        
        for i, line in enumerate(lines):
            # å®Ÿè¡Œè¨˜éŒ²ã®ãƒ˜ãƒƒãƒ€ãƒ¼
            if match := re.match(r'^##\s*å®Ÿè¡Œè¨˜éŒ²:\s*(.+)$', line):
                sections['execution_header'] = f"å®Ÿè¡Œè¨˜éŒ²: {match.group(1)}"
                current_section = 'metadata'
                continue
            
            # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆæ¥ç¶šå…ˆã€ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ï¼‰
            if current_section == 'metadata' and '**' in line:
                # **ã‚’é™¤å»ã—ã¦ã‚¯ãƒªãƒ¼ãƒ³ãªå½¢å¼ã«
                clean_line = re.sub(r'\*\*([^:]+):\*\*\s*(.+)', r'\1: \2', line)
                if clean_line != line:  # å¤‰æ›ãŒæˆåŠŸã—ãŸå ´åˆã®ã¿è¿½åŠ 
                    metadata_lines.append(clean_line)
                continue
            
            # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é–‹å§‹
            if re.match(r'^###\s+ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ', line):
                sections['prompt_title'] = 'ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ'
                prompt_start = i + 1
                current_section = 'prompt'
                continue
            
            # çµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®é–‹å§‹
            if re.match(r'^###\s+çµæœ', line):
                sections['result_title'] = 'çµæœ'
                result_start = i + 1
                current_section = 'result'
                # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®çµ‚äº†
                if prompt_start >= 0 and result_start > prompt_start:
                    prompt_lines = lines[prompt_start:i]
                continue
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹ã®å‡¦ç†
        if prompt_lines:
            # > [!NOTE] ãªã©ã®ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã¨å¼•ç”¨è¨˜å·ã‚’é™¤å»
            clean_prompt_lines = []
            skip_next = False
            for line in prompt_lines:
                if line.startswith('> [!'):
                    skip_next = True
                    continue
                if skip_next and line.startswith('> **'):
                    skip_next = False
                    continue
                # å¼•ç”¨è¨˜å·ã‚’é™¤å»
                if line.startswith('>'):
                    clean_line = line[1:].lstrip()
                    if clean_line or line == '>':  # ç©ºè¡Œã‚‚ä¿æŒ
                        clean_prompt_lines.append(clean_line)
                elif line.strip() and not line.startswith('#'):
                    clean_prompt_lines.append(line)
            
            sections['prompt_content'] = '\n'.join(clean_prompt_lines).strip()
        
        # çµæœå†…å®¹ã®å‡¦ç†
        if result_start >= 0:
            # çµæœã®çµ‚ã‚ã‚Šã‚’è¦‹ã¤ã‘ã‚‹ï¼ˆæ¬¡ã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã¾ãŸã¯ãƒ•ã‚¡ã‚¤ãƒ«ã®çµ‚ã‚ã‚Šï¼‰
            result_end = len(lines)
            for i in range(result_start, len(lines)):
                # åŒºåˆ‡ã‚Šç·šï¼ˆãƒ•ãƒ­ãƒ³ãƒˆãƒã‚¿ãƒ¼ï¼‰ã‚’æ¤œå‡º
                if lines[i].startswith('---') and i > result_start:
                    result_end = i
                    break
                # æ–°ã—ã„å®Ÿè¡Œè¨˜éŒ²ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œå‡ºï¼ˆåˆ¥ã®remote-claudeå®Ÿè¡Œï¼‰
                if re.match(r'^##\s+å®Ÿè¡Œè¨˜éŒ²:', lines[i]) and i > result_start:
                    result_end = i
                    break
                # æ³¨æ„: çµæœå†…ã® ## ã¯å«ã‚ã‚‹ï¼ˆClaude ã®å¿œç­”ã®ä¸€éƒ¨ãªã®ã§ï¼‰
            
            result_lines = lines[result_start:result_end]
            
            # çµæœå†…å®¹ã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
            clean_result_lines = []
            for line in result_lines:
                # å¼•ç”¨è¨˜å·ãŒã‚ã‚‹å ´åˆã¯é™¤å»
                if line.startswith('>'):
                    clean_line = line[1:].lstrip()
                    clean_result_lines.append(clean_line)
                else:
                    clean_result_lines.append(line)
            
            sections['result_content'] = '\n'.join(clean_result_lines).strip()
            
            logging.info(f"çµæœã‚»ã‚¯ã‚·ãƒ§ãƒ³: {result_start}è¡Œç›®ã‹ã‚‰{result_end}è¡Œç›®ã¾ã§")
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¨­å®š
        if metadata_lines:
            sections['metadata'] = metadata_lines
        
        # ãƒ‡ãƒãƒƒã‚°æƒ…å ±
        logging.info(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå†…å®¹ã®é•·ã•: {len(sections.get('prompt_content', ''))} æ–‡å­—")
        logging.info(f"çµæœå†…å®¹ã®é•·ã•: {len(sections.get('result_content', ''))} æ–‡å­—")
        
        return sections
    
    def _create_result_blocks(self, result_content: str, md_dir: Path) -> List[Dict[str, Any]]:
        """çµæœå†…å®¹ã‹ã‚‰Notionãƒ–ãƒ­ãƒƒã‚¯ã‚’ä½œæˆï¼ˆãƒˆã‚°ãƒ«å†…ç”¨ï¼‰"""
        if not result_content:
            logging.warning("çµæœå†…å®¹ãŒç©ºã§ã™")
            return []
        
        blocks = []
        
        logging.info(f"çµæœå†…å®¹ã‚’Markdownã¨ã—ã¦å‡¦ç†: {result_content[:100]}...")
        
        # çµæœã®å†…å®¹ã‚’å‡¦ç†
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã®å„è¦ç´ ã‚’é©åˆ‡ã«å¤‰æ›
        tokens = self.md.parse(result_content)
        
        logging.info(f"ãƒˆãƒ¼ã‚¯ãƒ³æ•°: {len(tokens)}")
        
        i = 0
        while i < len(tokens):
            token = tokens[i]
            t = token.type
            
            logging.debug(f"ãƒˆãƒ¼ã‚¯ãƒ³ {i}: {t}")
            
            if t == 'heading_open':
                i = self._process_heading_for_toggle(tokens, i, blocks)
            elif t in ('bullet_list_open', 'ordered_list_open'):
                i = self._process_list_for_toggle(tokens, i, blocks)
            elif t == 'paragraph_open':
                i = self._process_paragraph_for_toggle(tokens, i, blocks, md_dir)
            elif t == 'fence':
                i = self._process_code_block(tokens, i, blocks)
            elif t == 'blockquote_open':
                i = self._process_blockquote_for_toggle(tokens, i, blocks)
            elif t == 'hr':
                blocks.append({'object': 'block', 'type': 'divider', 'divider': {}})
                i += 1
            elif t == 'inline':
                # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³è¦ç´ ã®å‡¦ç†
                txt = token.content.strip()
                if txt:
                    blocks.append({
                        'object': 'block',
                        'type': 'paragraph',
                        'paragraph': {'rich_text': [{'type': 'text', 'text': {'content': txt}}]}
                    })
                i += 1
            else:
                i += 1
        
        logging.info(f"ç”Ÿæˆã•ã‚ŒãŸãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(blocks)}")
        
        return blocks
    
    def _process_heading_for_toggle(self, tokens, i: int, blocks: List[Dict]) -> int:
        """ãƒˆã‚°ãƒ«å†…ã®è¦‹å‡ºã—ã‚’å‡¦ç†"""
        token = tokens[i]
        lvl = int(token.tag[1])
        content = tokens[i+1].content
        
        # ãƒˆã‚°ãƒ«å†…ã§ã¯è¦‹å‡ºã—ãƒ¬ãƒ™ãƒ«ã‚’èª¿æ•´ã—ãªã„ï¼ˆå…ƒã®ãƒ¬ãƒ™ãƒ«ã‚’ç¶­æŒï¼‰
        blk = f"heading_{min(lvl, 3)}"  # æœ€å¤§h3ã¾ã§
        
        blocks.append({
            'object': 'block',
            'type': blk,
            blk: {'rich_text': [{'type': 'text', 'text': {'content': content}}]}
        })
        
        logging.debug(f"è¦‹å‡ºã—ã‚’è¿½åŠ : {content}")
        
        return i + 3
    
    def _process_list_for_toggle(self, tokens, i: int, blocks: List[Dict]) -> int:
        """ãƒˆã‚°ãƒ«å†…ã®ãƒªã‚¹ãƒˆã‚’å‡¦ç†"""
        list_type = 'numbered_list_item' if tokens[i].type == 'ordered_list_open' else 'bulleted_list_item'
        i += 1
        
        while i < len(tokens) and tokens[i].type not in ('bullet_list_close', 'ordered_list_close'):
            if tokens[i].type == 'list_item_open':
                # ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã®å†…å®¹ã‚’å–å¾—
                content_idx = i + 2
                if content_idx < len(tokens):
                    txt = tokens[content_idx].content
                    
                    blocks.append({
                        'object': 'block',
                        'type': list_type,
                        list_type: {'rich_text': [{'type': 'text', 'text': {'content': txt}}]}
                    })
                    
                    logging.debug(f"ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã‚’è¿½åŠ : {txt[:50]}...")
                
                # æ¬¡ã®ãƒªã‚¹ãƒˆã‚¢ã‚¤ãƒ†ãƒ ã¸
                i += 5
            else:
                i += 1
        
        return i + 1
    
    def _process_paragraph_for_toggle(self, tokens, i: int, blocks: List[Dict], md_dir: Path) -> int:
        """ãƒˆã‚°ãƒ«å†…ã®æ®µè½ã‚’å‡¦ç†"""
        if i + 1 < len(tokens):
            txt = tokens[i+1].content.strip()
            if txt:
                # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æ•°å¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
                inline_math_pattern = r'\$([^$\n]+)\$'
                
                # ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ãƒã‚§ãƒƒã‚¯
                block_math_pattern = r'\$\$\s*(.*?)\s*\$\$'
                block_math_match = re.search(block_math_pattern, txt, re.DOTALL)
                
                if block_math_match:
                    math_content = block_math_match.group(1).strip()
                    blocks.append({
                        'object': 'block',
                        'type': 'equation',
                        'equation': {'expression': math_content}
                    })
                    logging.debug(f"æ•°å¼ã‚’è¿½åŠ : {math_content[:30]}...")
                else:
                    # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æ•°å¼ã‚’ãƒã‚§ãƒƒã‚¯
                    inline_math_matches = list(re.finditer(inline_math_pattern, txt))
                    if inline_math_matches:
                        self._process_inline_math(txt, inline_math_matches, blocks)
                    else:
                        # é€šå¸¸ã®ãƒ†ã‚­ã‚¹ãƒˆå‡¦ç†
                        blocks.append({
                            'object': 'block',
                            'type': 'paragraph',
                            'paragraph': {'rich_text': [{'type': 'text', 'text': {'content': txt}}]}
                        })
                        logging.debug(f"æ®µè½ã‚’è¿½åŠ : {txt[:50]}...")
        
        return i + 2
    
    def _process_blockquote_for_toggle(self, tokens, i: int, blocks: List[Dict]) -> int:
        """ãƒˆã‚°ãƒ«å†…ã®å¼•ç”¨ã‚’å‡¦ç†"""
        i += 1
        content_lines = []
        
        while i < len(tokens) and tokens[i].type != 'blockquote_close':
            if tokens[i].type == 'paragraph_open':
                if i + 1 < len(tokens):
                    content_lines.append(tokens[i+1].content)
                i += 2
            i += 1
        
        if content_lines:
            content = '\n'.join(content_lines)
            blocks.append({
                'object': 'block',
                'type': 'quote',
                'quote': {'rich_text': [{'type': 'text', 'text': {'content': content}}]}
            })
        
        return i + 1
    
    def _process_code_block(self, tokens, i: int, blocks: List[Dict]) -> int:
        """ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‡¦ç†"""
        token = tokens[i]
        language = token.info or 'plain text'
        content = token.content
        
        # Notion APIã§ç„¡åŠ¹ãªè¨€èªåã‚’å¤‰æ›
        language_mapping = {
            'text': 'plain text',
            'txt': 'plain text',
            'plaintext': 'plain text',
            'sh': 'shell',
            'bash': 'shell',
            'zsh': 'shell',
            'js': 'javascript',
            'ts': 'typescript',
            'py': 'python',
            'rb': 'ruby',
            'yml': 'yaml',
            'md': 'markdown',
            '': 'plain text'
        }
        
        # è¨€èªåã®æ­£è¦åŒ–
        normalized_language = language.lower().strip()
        if normalized_language in language_mapping:
            language = language_mapping[normalized_language]
        elif normalized_language == '':
            language = 'plain text'
        
        # æ•°å¼ã¨ã—ã¦å‡¦ç†ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        if normalized_language in ('math', 'latex', 'tex'):
            blocks.append({
                'object': 'block',
                'type': 'equation',
                'equation': {'expression': content}
            })
        else:
            blocks.append({
                'object': 'block',
                'type': 'code',
                'code': {
                    'language': language,
                    'rich_text': [{'type': 'text', 'text': {'content': content}}]
                }
            })
        
        return i + 1
    
    def _process_inline_math(self, text: str, matches, blocks: List[Dict]):
        """ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æ•°å¼ã‚’å«ã‚€ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†"""
        if not matches:
            blocks.append({
                'object': 'block',
                'type': 'paragraph',
                'paragraph': {'rich_text': [{'type': 'text', 'text': {'content': text}}]}
            })
            return
        
        rich_text = []
        last_end = 0
        
        for match in matches:
            # æ•°å¼å‰ã®ãƒ†ã‚­ã‚¹ãƒˆ
            if match.start() > last_end:
                rich_text.append({
                    'type': 'text',
                    'text': {'content': text[last_end:match.start()]}
                })
            
            # æ•°å¼
            math_content = match.group(1)
            rich_text.append({
                'type': 'equation',
                'equation': {'expression': math_content}
            })
            
            last_end = match.end()
        
        # æ®‹ã‚Šã®ãƒ†ã‚­ã‚¹ãƒˆ
        if last_end < len(text):
            rich_text.append({
                'type': 'text',
                'text': {'content': text[last_end:]}
            })
        
        blocks.append({
            'object': 'block',
            'type': 'paragraph',
            'paragraph': {'rich_text': rich_text}
        })
    
    def _process_callouts(self, md_text: str) -> str:
        """Obsidianã‚¹ã‚¿ã‚¤ãƒ«ã®ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’å‡¦ç†"""
        lines = md_text.split('\n')
        processed_lines = []
        i = 0
        
        while i < len(lines):
            line = lines[i]
            
            # ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®é–‹å§‹ã‚’æ¤œå‡º
            callout_match = re.match(r'>\s*\[!(\w+)\](?:\s*(.*))?', line)
            if callout_match:
                callout_type = callout_match.group(1).upper()
                callout_title = callout_match.group(2) or callout_type.title()
                
                # ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã®å†…å®¹ã‚’åé›†
                callout_content = []
                i += 1
                
                while i < len(lines) and (lines[i].startswith('>') or lines[i].strip() == ''):
                    content_line = lines[i]
                    if content_line.startswith('>'):
                        content_line = content_line[1:].lstrip()
                    callout_content.append(content_line)
                    i += 1
                
                # ã‚³ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆã‚’Markdownå¼•ç”¨ã«å¤‰æ›
                emoji = self.parser.CALLOUT_TYPES.get(callout_type, 'ğŸ“')
                processed_lines.append(f'> **{emoji} {callout_title}**')
                processed_lines.append('>')
                for content in callout_content:
                    if content.strip():
                        processed_lines.append(f'> {content}')
                    else:
                        processed_lines.append('>')
                
                continue
            
            processed_lines.append(line)
            i += 1
        
        return '\n'.join(processed_lines)
    
    def _process_text_with_block_math(self, md_text: str, md_dir: Path, blocks: List[Dict]):
        """ãƒ†ã‚­ã‚¹ãƒˆã‚’å‡¦ç†ã—ã¦ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã‚’æ¤œå‡º"""
        # ãƒ–ãƒ­ãƒƒã‚¯æ•°å¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
        block_math_pattern = r'\$\$\s*(.*?)\s*\$\$'
        
        # ãƒ†ã‚­ã‚¹ãƒˆã‚’åˆ†å‰²
        parts = re.split(block_math_pattern, md_text, flags=re.DOTALL)
        
        for i, part in enumerate(parts):
            if not part.strip():
                continue
                
            if i % 2 == 1:  # æ•°å¼éƒ¨åˆ†
                blocks.append({
                    'object': 'block',
                    'type': 'equation',
                    'equation': {'expression': part.strip()}
                })
            else:  # é€šå¸¸ã®Markdownéƒ¨åˆ†
                # é€šå¸¸ã®Markdownå‡¦ç†
                tokens = self.md.parse(part)
                j = 0
                while j < len(tokens):
                    token = tokens[j]
                    t = token.type
                    
                    if t == 'heading_open':
                        j = self._process_heading(tokens, j, blocks)
                    elif t in ('bullet_list_open', 'ordered_list_open'):
                        j = self._process_list(tokens, j, blocks)
                    elif t == 'paragraph_open':
                        j = self._process_paragraph(tokens, j, blocks, md_dir)
                    elif t == 'fence':
                        j = self._process_code_block(tokens, j, blocks)
                    elif t == 'blockquote_open':
                        j = self._process_blockquote(tokens, j, blocks)
                    elif t == 'hr':
                        blocks.append({'object': 'block', 'type': 'divider', 'divider': {}})
                        j += 1
                    else:
                        j += 1
    
    def _process_heading(self, tokens, i: int, blocks: List[Dict]) -> int:
        """è¦‹å‡ºã—ã‚’å‡¦ç†"""
        token = tokens[i]
        level = int(token.tag[1])
        content = tokens[i+1].content
        
        heading_type = f"heading_{min(level, 3)}"
        blocks.append({
            'object': 'block',
            'type': heading_type,
            heading_type: {'rich_text': [{'type': 'text', 'text': {'content': content}}]}
        })
        
        return i + 3
    
    def _process_list(self, tokens, i: int, blocks: List[Dict]) -> int:
        """ãƒªã‚¹ãƒˆã‚’å‡¦ç†"""
        list_type = 'numbered_list_item' if tokens[i].type == 'ordered_list_open' else 'bulleted_list_item'
        i += 1
        
        while i < len(tokens) and tokens[i].type not in ('bullet_list_close', 'ordered_list_close'):
            if tokens[i].type == 'list_item_open':
                content_idx = i + 2
                if content_idx < len(tokens):
                    txt = tokens[content_idx].content
                    blocks.append({
                        'object': 'block',
                        'type': list_type,
                        list_type: {'rich_text': [{'type': 'text', 'text': {'content': txt}}]}
                    })
                i += 5
            else:
                i += 1
        
        return i + 1
    
    def _process_paragraph(self, tokens, i: int, blocks: List[Dict], md_dir: Path) -> int:
        """æ®µè½ã‚’å‡¦ç†"""
        if i + 1 < len(tokens):
            txt = tokens[i+1].content.strip()
            if txt:
                # ç”»åƒã®å‡¦ç†
                img_pattern = r'!\[([^\]]*)\]\(([^)]+)\)'
                img_match = re.search(img_pattern, txt)
                
                if img_match:
                    alt_text = img_match.group(1)
                    img_path = img_match.group(2)
                    
                    # ç›¸å¯¾ãƒ‘ã‚¹ã‚’çµ¶å¯¾ãƒ‘ã‚¹ã«å¤‰æ›
                    if not img_path.startswith(('http://', 'https://')):
                        full_img_path = md_dir / img_path
                        img_url = self.image_uploader.get_image_url(full_img_path)
                    else:
                        img_url = img_path
                    
                    blocks.append({
                        'object': 'block',
                        'type': 'image',
                        'image': {'external': {'url': img_url}}
                    })
                else:
                    # ã‚¤ãƒ³ãƒ©ã‚¤ãƒ³æ•°å¼ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
                    inline_math_pattern = r'\$([^$\n]+)\$'
                    inline_math_matches = list(re.finditer(inline_math_pattern, txt))
                    
                    if inline_math_matches:
                        self._process_inline_math(txt, inline_math_matches, blocks)
                    else:
                        blocks.append({
                            'object': 'block',
                            'type': 'paragraph',
                            'paragraph': {'rich_text': [{'type': 'text', 'text': {'content': txt}}]}
                        })
        
        return i + 2
    
    def _process_blockquote(self, tokens, i: int, blocks: List[Dict]) -> int:
        """å¼•ç”¨ãƒ–ãƒ­ãƒƒã‚¯ã‚’å‡¦ç†"""
        i += 1
        content_lines = []
        
        while i < len(tokens) and tokens[i].type != 'blockquote_close':
            if tokens[i].type == 'paragraph_open':
                if i + 1 < len(tokens):
                    content_lines.append(tokens[i+1].content)
                i += 2
            i += 1
        
        if content_lines:
            content = '\n'.join(content_lines)
            blocks.append({
                'object': 'block',
                'type': 'quote',
                'quote': {'rich_text': [{'type': 'text', 'text': {'content': content}}]}
            })
        
        return i + 1
    
    def _validate_blocks(self, blocks: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ãƒ–ãƒ­ãƒƒã‚¯ã‚’æ¤œè¨¼ã—ã¦åˆ¶é™ã«æº–æ‹ ã•ã›ã‚‹"""
        validated_blocks = []
        
        for block in blocks:
            # ãƒ–ãƒ­ãƒƒã‚¯æ•°ã®åˆ¶é™ãƒã‚§ãƒƒã‚¯
            if len(validated_blocks) >= self.config.max_blocks_per_page:
                logging.warning(f"ãƒ–ãƒ­ãƒƒã‚¯æ•°ãŒåˆ¶é™({self.config.max_blocks_per_page})ã«é”ã—ã¾ã—ãŸ")
                break
            
            # rich_textã®é•·ã•åˆ¶é™ãƒã‚§ãƒƒã‚¯
            self._validate_rich_text_length(block)
            
            # ãƒˆã‚°ãƒ«ãƒ–ãƒ­ãƒƒã‚¯ã®å­è¦ç´ ã‚‚æ¤œè¨¼
            if block.get('type') == 'toggle' and 'toggle' in block and 'children' in block['toggle']:
                children = block['toggle']['children']
                validated_children = []
                
                for child in children:
                    if len(validated_children) < 50:  # ãƒˆã‚°ãƒ«å†…ã®å­è¦ç´ åˆ¶é™
                        self._validate_rich_text_length(child)
                        validated_children.append(child)
                    else:
                        logging.warning("ãƒˆã‚°ãƒ«å†…ã®å­è¦ç´ ãŒåˆ¶é™ã«é”ã—ã¾ã—ãŸ")
                        break
                
                block['toggle']['children'] = validated_children
            
            validated_blocks.append(block)
        
        return validated_blocks
    
    def _validate_rich_text_length(self, block: Dict[str, Any]):
        """rich_textã®é•·ã•ã‚’åˆ¶é™å†…ã«åã‚ã‚‹"""
        if 'paragraph' in block:
            self._truncate_rich_text(block['paragraph'])
        elif 'heading_1' in block:
            self._truncate_rich_text(block['heading_1'])
        elif 'heading_2' in block:
            self._truncate_rich_text(block['heading_2'])
        elif 'heading_3' in block:
            self._truncate_rich_text(block['heading_3'])
        elif 'quote' in block:
            self._truncate_rich_text(block['quote'])
        elif 'bulleted_list_item' in block:
            self._truncate_rich_text(block['bulleted_list_item'])
        elif 'numbered_list_item' in block:
            self._truncate_rich_text(block['numbered_list_item'])
        elif 'toggle' in block:
            self._truncate_rich_text(block['toggle'])
        elif 'callout' in block:
            self._truncate_rich_text(block['callout'])
    
    def _truncate_rich_text(self, block_content: Dict[str, Any]):
        """rich_textã‚’åˆ¶é™å†…ã«åˆ‡ã‚Šè©°ã‚ã‚‹"""
        if 'rich_text' in block_content:
            rich_text_list = block_content['rich_text']
            total_length = 0
            truncated_rich_text = []
            
            for rt in rich_text_list:
                if rt.get('type') == 'text':
                    text_content = rt['text']['content']
                    remaining_length = self.config.max_rich_text_length - total_length
                    
                    if len(text_content) <= remaining_length:
                        truncated_rich_text.append(rt)
                        total_length += len(text_content)
                    else:
                        # åˆ‡ã‚Šè©°ã‚ã‚‹
                        truncated_text = text_content[:remaining_length - 3] + '...'
                        rt['text']['content'] = truncated_text
                        truncated_rich_text.append(rt)
                        break
                else:
                    truncated_rich_text.append(rt)
            
            block_content['rich_text'] = truncated_rich_text